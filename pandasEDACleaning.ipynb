{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e6577",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"pandasEDACleaning.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18812168d290ea6",
   "metadata": {},
   "source": [
    "## Lecture Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c6227ff40b1749",
   "metadata": {},
   "source": [
    "In this lecture, we will cover more of the `pandas` library.\n",
    "Specifically:\n",
    "\n",
    "* Cleaning Data\n",
    "    * Replacing `None` values\n",
    "    * Changing data types/formats\n",
    "    * Removing duplicate rows\n",
    "* Exploratory Data Analysis\n",
    "    * Finding mean, median, mode of a column\n",
    "    * Summarizing the data\n",
    "    * Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801be9d24a03df5",
   "metadata": {},
   "source": [
    "We will be working with the synthetic (not-real-world data) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279209b60848745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:28.924932800Z",
     "start_time": "2026-02-23T18:42:28.894095900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/synthetic_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e5e73ac31d43d",
   "metadata": {},
   "source": [
    "First, we want to see the general information about our dataset. Use `.info()` to do this in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f096aac18f0ba016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:39:12.722243300Z",
     "start_time": "2026-02-23T18:39:12.534465500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80dcd561ace8ce08",
   "metadata": {},
   "source": [
    "Take note of how many rows there are in the dataset. Which columns have missing data? Are any of the columns the wrong type?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db0544cc98a6ae",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ecc241e97bb3",
   "metadata": {},
   "source": [
    "Let's handle the missing data first. We have three options. We can remove the rows that have missing data, fill in the missing data with a different value, or we can fill in the missing data with a different value depending on the column of the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ffb4e07ce30a7d",
   "metadata": {},
   "source": [
    "**Drop rows with missing data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd6b4d5e1ad0de",
   "metadata": {},
   "source": [
    "Replace the `XXX` with the `.dropna()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c49f4c4719e5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:39:13.211284800Z",
     "start_time": "2026-02-23T18:39:12.889561300Z"
    }
   },
   "outputs": [],
   "source": [
    "dropped_rows = df.XXX\n",
    "dropped_rows.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30c6a07cc287ac3",
   "metadata": {},
   "source": [
    "**Changing all missing data to some value**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e547d45958d047c1",
   "metadata": {},
   "source": [
    "Replace the `XXX` with the `.fillna()` method. Pass 130 as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df0580357152db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:41:59.007396700Z",
     "start_time": "2026-02-23T18:41:58.710061700Z"
    }
   },
   "outputs": [],
   "source": [
    "df_replaced_130 = df.XXX\n",
    "df_replaced_130.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78926212d510ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:03.290664800Z",
     "start_time": "2026-02-23T18:42:03.004709300Z"
    }
   },
   "outputs": [],
   "source": [
    "df_replaced_130.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156da70c60414bd4",
   "metadata": {},
   "source": [
    "**Change missing values to some value based on column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab3c41c2d6278e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:40.305968600Z",
     "start_time": "2026-02-23T18:42:40.265450900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new_stat = df.fillna({\"Status\": 'Missing'}) # replace NAs with a blanket value\n",
    "df_new_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1b1a97e558a7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:42.286179800Z",
     "start_time": "2026-02-23T18:42:42.242991Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new_stat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61992772540f354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:43.987097100Z",
     "start_time": "2026-02-23T18:42:43.949258500Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new_stat.fillna({\"Score\":df['Score'].mean()}, inplace=True) # replace it with the average of column\n",
    "df_new_stat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f1e2fc181a784",
   "metadata": {},
   "source": [
    "To find the median or mode, we can use `.median()` and `.mode()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae4e590050f0d70",
   "metadata": {},
   "source": [
    "Now we want to fix the JoinDate column. Some of the entries don't look like dates, so we will use `.to_datetime()` to fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e83ca3434337f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:45.947690500Z",
     "start_time": "2026-02-23T18:42:45.896402400Z"
    }
   },
   "outputs": [],
   "source": [
    "df['JoinDate'] = pd.to_datetime(df['JoinDate'].str.strip(\"'\"))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c525f916231feb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:47.667485400Z",
     "start_time": "2026-02-23T18:42:47.627154600Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b20d4c45f70033",
   "metadata": {},
   "source": [
    "What if we know a value is wrong? For example, row 1 has a score of 120.9, but all other rows have scores between 0 and 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3735c9c29279e06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:50.012657400Z",
     "start_time": "2026-02-23T18:42:49.982163200Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[1, \"Score\"] = 100 # change single value\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b838602e58ffd9",
   "metadata": {},
   "source": [
    "We can change it one-by-one like above, or we can make a rule and change multiple rows at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8289765925b4b53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:51.460168500Z",
     "start_time": "2026-02-23T18:42:51.411504500Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in df.index:\n",
    "    if df.loc[x, \"Score\"] > 100:\n",
    "        df.loc[x, \"Score\"] = 100\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91bf07567f2cef",
   "metadata": {},
   "source": [
    "Another option is to use `.drop(index)` and remove the row with the wrong data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68257626b35618",
   "metadata": {},
   "source": [
    "Finally, let's check for duplicated rows using `.duplicated()`. Try it in the code block below. How many rows are duplicated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e28d8af4de04c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:53.561536600Z",
     "start_time": "2026-02-23T18:42:53.532109200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b09655e8f29634b",
   "metadata": {},
   "source": [
    "We can remove the duplicated rows with `drop_duplicates()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e1ef9988e735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:42:54.873542500Z",
     "start_time": "2026-02-23T18:42:54.836157900Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b139a7c392f6bb9",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaa275c5b0a1f6",
   "metadata": {},
   "source": [
    "We have already covered some aspects of EDA. For example, `.info()` tells us how many rows we have, of what types, and how many NA values exist within each of our columns. We also used `.mean()` a few moments ago, and we can use `.mode()` and `.median()` in a similar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095634236db98de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:43:31.889121300Z",
     "start_time": "2026-02-23T18:43:31.844320900Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df['Score'].mean())\n",
    "print(df['Score'].mode(0)) #NaN because there are no duplicates\n",
    "                        # 0 means by column, 1 by row\n",
    "print(df['Score'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5742fcf795d0deb4",
   "metadata": {},
   "source": [
    "We will continue to introduce aspects of EDA in Python throughout other lectures. However, we will introduce one more function now: `corr()`. `corr()` returns a correlation matrix of the *features in your dataframe.\n",
    "\n",
    "* features are also known as your independant variables, or x's.\n",
    "\n",
    "`corr()` only works with numeric columns. Since we only have Score, we could convert Status to a numeric mapping and run `corr()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fa121a4fe0154",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:43:33.651661700Z",
     "start_time": "2026-02-23T18:43:33.604513900Z"
    }
   },
   "outputs": [],
   "source": [
    "status_map = {\n",
    "    'Pending': 0,\n",
    "    'Missing': 1,\n",
    "    'Inactive': 2,\n",
    "    'Active': 3\n",
    "}\n",
    "\n",
    "df['Status_Num'] = df['Status'].map(status_map)\n",
    "new_df = df[['Status_Num', 'Score']]\n",
    "correlation = new_df.corr()\n",
    "print(correlation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15461f3e955ba05a",
   "metadata": {},
   "source": [
    "Another option is to create `dummy` variables out of Status. This will give us a correlation between each Status and the Score variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f0cdbc96d47ea9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:43:47.275479Z",
     "start_time": "2026-02-23T18:43:47.231569300Z"
    }
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df['Status'], prefix='Status')\n",
    "new_df = pd.concat([dummies, df['Score']], axis=1)\n",
    "correlation_matrix = new_df.corr()\n",
    "print(correlation_matrix['Score'].drop('Score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea4bfed80004ae",
   "metadata": {},
   "source": [
    "We can tell from both that there is not much of a correlation to be found, because the synthetic data was created randomly.\n",
    "\n",
    "In a future lecture, we will see how to turn the correlations into heatmaps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584757234245703",
   "metadata": {},
   "source": [
    "## Assignment Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab5dd4fb346b647",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.**\n",
    "\n",
    "We will borrow a dataset from Kaggle for this exercise. I have edited it for the purposes of this course.\n",
    "https://www.kaggle.com/datasets/msjahid/colorado-motor-vehicle-sales-data\n",
    "\n",
    "For this problem, you will use `pandas` to read the `\"data/colorado_motor_vehicle_sales.csv\"` file.\n",
    "The dataset has missing information:\n",
    "* Replace null data in the `sales` column with `0`.\n",
    "* If the country is \"xxx\", replace it with \"NA\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4fa22acebb6b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:43:47.340002700Z",
     "start_time": "2026-02-23T18:43:47.302287900Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/colorado_motor_vehicle_sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b86fcb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085c970df8eb22c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.**\n",
    "Using the same dataframe from Question 1, change the `0`s in the `sales` column to the mean of the `sales` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf79ad24f0d0a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:43:47.411858400Z",
     "start_time": "2026-02-23T18:43:47.401917800Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b7026",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a6d87550ca11d4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.**\n",
    "\n",
    "Using the same dataframe as Question2:\n",
    "* Find the correlation between quarter and sales and save the matrix in `correlation_quarter`\n",
    "* Find the correlation between year and sales and save the matrix in `correlation_year`\n",
    "* Using the example in the lecture, create a dummy variable of `year` (use `prefix = \"q\"`), then find the correlation between the dummy variable and `sales`. Save the output to `correlation_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ff4792bebe451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T18:43:47.455243200Z",
     "start_time": "2026-02-23T18:43:47.430324100Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "correlation_quarter = ...\n",
    "\n",
    "correlation_year = ...\n",
    "print(correlation_quarter)\n",
    "print(correlation_year)\n",
    "\n",
    "\n",
    "dummies = ...\n",
    "new_df_quart_sep = ...\n",
    "correlation_matrix = ...\n",
    "print(correlation_matrix['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f0bb9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e789b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51175271",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (otter)",
   "language": "python",
   "name": "otter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'xxx' not in df['county'].values\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert None not in df['sales'].values\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert m < df['sales'].mean()\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> import numpy as np\n>>> assert np.isclose(df['sales'].mean(), 174115185.9891745, rtol=1e-05, atol=1e-08, equal_nan=False)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import numpy as np\n>>> assert np.isclose(correlation_year['year']['sales'], 0.169835)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> import numpy as np\n>>> assert np.isclose(correlation_quarter['quarter']['sales'], 0.034802)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> import numpy as np\n>>> assert np.isclose(correlation_matrix['sales']['q_2008'], -0.030782)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> import numpy as np\n>>> assert np.isclose(correlation_matrix['sales']['q_2011'], 0.038025)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
